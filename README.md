# LangChain Tutorial ğŸ¦œğŸ”—

A comprehensive hands-on tutorial project for learning LangChain fundamentals, covering everything from basic chat models to advanced ReAct agents with tool integration.

## ğŸ“š Overview

This repository contains practical examples and implementations demonstrating core LangChain concepts, organized into progressive chapters. Each example is designed to be self-contained and easy to understand, making it perfect for both beginners and intermediate developers looking to master LangChain.

## âœ¨ Features

### Chapter 1: Foundation - Chat Models & Prompts
- **ChatOpenAI**: Direct integration with OpenAI's chat models
- **InitChatModel**: Model initialization patterns and best practices
- **Messages**: Working with different message types and formats
- **Prompts**: Template-based prompt engineering (Parts 1 & 2)
- **Structured Output**: Type-safe responses with Pydantic models

### Chapter 2: Chains & Composition
- **First Chain**: Building your first LangChain pipeline
- **Runnable**: Understanding the Runnable interface
- **Custom Runnable**: Creating custom chain components
- **Parallel Chains**: Executing multiple chains concurrently
- **Conditional Chains**: Dynamic routing and branching logic

### Chapter 3: Agents & Tools
- **ReAct Agent**: Reasoning + Acting pattern with tool integration
- **ReAct DB Agent**: Database-aware agents for data queries

## ğŸ› ï¸ Tech Stack

- **Python**: 3.11+
- **LangChain**: Core framework for LLM applications
- **OpenAI**: GPT models integration
- **SQLAlchemy**: Database ORM
- **PostgreSQL**: Database backend (psycopg2-binary)
- **Wikipedia API**: Knowledge base integration
- **UV**: Fast Python package manager

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- Python 3.11 or higher installed
- An OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- UV package manager (recommended) or pip
- PostgreSQL (for database examples)

## ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/langchain-tutorial.git
cd langchain-tutorial
```

### 2. Install UV (if not already installed)

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 3. Install dependencies

```bash
uv sync
```

Or using pip:

```bash
pip install -r requirements.txt
```

### 4. Set up environment variables

Create a `.env` file in the root directory:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

## ğŸ“‚ Project Structure

```
LangChain/
â”œâ”€â”€ Chapter1/              # Foundation concepts
â”‚   â”œâ”€â”€ 1_ChatOpenAI.py
â”‚   â”œâ”€â”€ 2_InitChatModel.py
â”‚   â”œâ”€â”€ 3_Messages.py
â”‚   â”œâ”€â”€ 4_Prompts1.py
â”‚   â”œâ”€â”€ 5_Prompts2.py
â”‚   â””â”€â”€ 6_Structured_Output.py
â”œâ”€â”€ Chapter2/              # Chains and composition
â”‚   â”œâ”€â”€ 1_FirstChain.py
â”‚   â”œâ”€â”€ 2_Runnable.py
â”‚   â”œâ”€â”€ 3_CustomRunnable.py
â”‚   â”œâ”€â”€ 4_ParallelChains.py
â”‚   â””â”€â”€ 5_ConditonalChains.py
â”œâ”€â”€ Chapter3/              # Agents and tools
â”‚   â”œâ”€â”€ 1_ReActAgent.py
â”‚   â””â”€â”€ 2_ReAct_DBAgent.py
â”œâ”€â”€ core/                  # Core configuration
â”‚   â”œâ”€â”€ config.py          # Environment settings
â”‚   â””â”€â”€ deps.py            # Dependencies
â”œâ”€â”€ database/              # Database utilities
â”‚   â””â”€â”€ db.py
â”œâ”€â”€ llms/                  # LLM factory patterns
â”‚   â””â”€â”€ factory.py
â”œâ”€â”€ models/                # Data models
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ pyproject.toml         # Project dependencies
â””â”€â”€ README.md
```

## ğŸ’» Usage

### Running Individual Examples

Navigate to any chapter and run the examples:

```bash
# Chapter 1 - Basic chat interaction
python Chapter1/1_ChatOpenAI.py

# Chapter 2 - Chain composition
python Chapter2/1_FirstChain.py

# Chapter 3 - ReAct agent with tools
python Chapter3/1_ReActAgent.py
```

### Using the LLM Factory

The project includes a factory pattern for model initialization:

```python
from llms.factory import get_openai_model_direct

# Initialize the model
llm = get_openai_model_direct()

# Use the model
response = llm.invoke("Your prompt here")
print(response.content)
```

## ğŸ¯ Key Concepts Covered

### 1. **Chat Models**
Learn how to initialize and interact with OpenAI's chat models, handle different message types, and work with model responses.

### 2. **Prompt Engineering**
Master template-based prompts, variable substitution, and structured prompt design for consistent outputs.

### 3. **Chains (LCEL)**
Build complex workflows using LangChain Expression Language (LCEL), compose chains, and handle parallel execution.

### 4. **Agents & Tools**
Implement ReAct (Reasoning + Acting) agents that can use external tools like web search, Wikipedia, and custom enterprise functions.

### 5. **Structured Outputs**
Work with type-safe responses using Pydantic models for reliable data extraction.

## ğŸ”§ Configuration

The project uses environment-based configuration managed through `core/config.py`:

```python
from core.config import settings

# Access configuration
api_key = settings["OPENAI_API_KEY"]
```

## ğŸ“¦ Dependencies

Key packages used in this project:

- `langchain` - Core LangChain framework
- `langchain-openai` - OpenAI integration
- `langchain-community` - Community tools (Wikipedia, DuckDuckGo)
- `openai` - Official OpenAI client
- `sqlalchemy` - Database ORM
- `psycopg2-binary` - PostgreSQL adapter
- `python-dotenv` - Environment variable management
- `wikipedia` - Wikipedia API wrapper

## ğŸ“– Learning Path

Recommended order for beginners:

1. **Start with Chapter 1** - Get comfortable with chat models and prompts
2. **Progress to Chapter 2** - Learn about chains and composition
3. **Advance to Chapter 3** - Master agents and tool integration
4. **Explore the core modules** - Understand the project architecture

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

- Report bugs
- Suggest new examples
- Improve documentation
- Add more chapters

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ”— Resources

- [LangChain Documentation](https://python.langchain.com/)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/expression_language/)
- [ReAct Paper](https://arxiv.org/abs/2210.03629)

## ğŸ’¡ Tips

- Always set your `OPENAI_API_KEY` before running examples
- Start with smaller models for testing (e.g., `gpt-3.5-turbo`)
- Review the comments in each file for detailed explanations
- Experiment with different prompts and parameters

## ğŸ™‹â€â™‚ï¸ Support

If you have questions or run into issues:

1. Check the code comments for inline documentation
2. Review the LangChain official docs
3. Open an issue in this repository

---

**Happy Learning! ğŸš€**

Built with â¤ï¸ using LangChain and OpenAI
